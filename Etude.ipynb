{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction : Ce notebook constitue ma participation à la compétition kaggle \"Spaceship Titanic\". \n",
    "\n",
    "L'objectif de l'étude est d'utiliser et d'optimiser un algorithme de Machine Learning de classification pour prévoir si un passager à survécu ou non. \n",
    "Deux datasets sont à disposition. Le premier, train.csv, comprend la variable cible à prédire \"Transported\" pour l'entrainement. Le second, test.csv est utilisé pour réaliser les prédictions. Le fichier sample_submission.csv est le fichier qui servira pour stocker les prédictions et les envoyer. \n",
    "\n",
    "La métrique de ce concours est l'accuracy. L'objectif principal est donc de modéliser un modèle prédictif de Machine Learning maximisant l'accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des packages nécessaires \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn import neighbors\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette='pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des DataFrames \n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "#Attention : toutes les modifications sur les df devront être faites dans les deux dataframes pour que l'algo de ML soit fonctionnel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Nettoyage des données \n",
    "\n",
    "Pour cet analyse mettant en oeuvre des algorithmes de Machine Learning, le nettoyage et la préparation des données est une étape absolument décisive. Des hypothèses on été posées et seules celles retenues figurent dans ce notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Inspection des données \n",
    "\n",
    "La première chose à faire avant d'explorer un jeu de données est de s'intéresser aux métadatas s'il y en a et aux informations qu'on a sur les données.\n",
    "En premier lieu, d'où viennent ces données ? Comment ces données ont-elles été collectées ? Quels types de fichiers a-t-on ? De quelles tailles ? Quelles sont les caractéristiques présentes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame train \n",
    "df_train.info()\n",
    "#Il y a 8693 entrées et 14 colonnes. \n",
    "#On observe qu'il y a de nombreux NaNs dans les colonnes constituant le df. \n",
    "#Nous n'avons pas de fichier metadata à notre disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame test\n",
    "df_test.info()\n",
    "#Il y a 4277 entrées et 13 colonnes. Nous n'avons pas ici la colonne target (Transported)\n",
    "#On observe qu'il y a de nombreux NaNs dans les colonnes constituant le df. \n",
    "#Nous n'avons pas de fichier metadata à notre disposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Vérification de la cohérence et de l'uniformité des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Cohérence des données\n",
    "Tout d'abord, il convient de vérifier que chaque variable est au bon type. L'objectif est d'avoir une uniformité des types de valeurs entre les 2 DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame train\n",
    "\n",
    "\n",
    "#PassengerId doit être en deux colonnes (PassengerGroup et PassengerGroupNumber) et en int\n",
    "df_train[['PassengerGroup','PassengerGroupNumber']]=df_train['PassengerId'].str.split('_', expand=True).astype(int)\n",
    "\n",
    "#CryoSleep doit être en booléen\n",
    "df_train.CryoSleep.unique() #A au moins un NaN, on refera une passe dessus après la gestion des valeurs manquantes\n",
    "\n",
    "#Cabin a mettre en 3 colonnes et en object / int / object\n",
    "df_train[['Deck','Num','Side']]=df_train['Cabin'].str.split('/', expand=True) #Contient des NaNs donc sera traité après la gestion des valeurs manquantes\n",
    "\n",
    "#VIP a mettre en booléen ATTENTION BIEN REGARDER AVEC UNIQUE SI PREND BIEN 2 TRUCS\n",
    "df_train['VIP'].unique() #Contient des NaNs donc sera traité après la gestion des valeurs manquantes\n",
    "\n",
    "#Les types des variables suivantes seront traités après le traitement des valeurs manquantes\n",
    "#Food court a mettre en int\n",
    "#Shopping mall a mettre en int\n",
    "#Spa a mettre en int \n",
    "#Age a mettre en int\n",
    "#Room service a mettre en int (vérifier l'explication sur le site)\n",
    "\n",
    "df_train.info()\n",
    "df_train.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des colonnes inutiles \n",
    "df_train=df_train.drop(['PassengerId','Cabin','Name'], axis = 1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame test\n",
    "\n",
    "#PassengerId doit être en deux colonnes (PassengerGroup et PassengerGroupNumber) et en int\n",
    "df_test[['PassengerGroup','PassengerGroupNumber']]=df_test['PassengerId'].str.split('_', expand=True).astype(int)\n",
    "\n",
    "#CryoSleep doit être en booléen\n",
    "df_test.CryoSleep.unique() #A au moins un NaN, on refera une passe dessus après la gestion des valeurs manquantes\n",
    "\n",
    "#Cabin a mettre en 3 colonnes et en object / int / object\n",
    "df_test[['Deck','Num','Side']]=df_test['Cabin'].str.split('/', expand=True) #Contient des NaNs donc sera traité après la gestion des valeurs manquantes\n",
    "\n",
    "#VIP a mettre en booléen ATTENTION BIEN REGARDER AVEC UNIQUE SI PREND BIEN 2 TRUCS\n",
    "df_test['VIP'].unique() #Contient des NaNs donc sera traité après la gestion des valeurs manquantes\n",
    "\n",
    "#Les types des variables suivantes seront traités après le traitement des valeurs manquantes\n",
    "#Food court a mettre en int\n",
    "#Shopping mall a mettre en int\n",
    "#Spa a mettre en int \n",
    "#Age a mettre en int\n",
    "#Room service a mettre en int (vérifier l'explication sur le site)\n",
    "\n",
    "df_test.info()\n",
    "df_test.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des colonnes inutiles \n",
    "df_test=df_test.drop(['PassengerId','Cabin','Name'], axis = 1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Uniformité des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il convient de vérifier que les variables qualitatives sont uniformes, c'est à dire qu'elles doivent être écrites toujours de la même manière en respectant une règle unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame Train \n",
    "#Les variables qualitatives sont : HomePlanet, Destination, Age, VIP, Transported, PassengerGroupNumber, Deck, Side \n",
    "df_train['HomePlanet'].unique() #Toutes les planètes sont écrites au même format\n",
    "\n",
    "df_train['Destination'].unique() #Toutes les destinations sont écrites au même format\n",
    "#Il est décidé de simplifier les noms et de les mettre en majuscule \n",
    "df_train['Destination']=df_train['Destination'].replace('TRAPPIST-1e','TRAPPIST')\n",
    "df_train['Destination']=df_train['Destination'].replace('55 Cancri e','CANCRI')\n",
    "df_train['Destination']=df_train['Destination'].replace('PSO J318.5-22','PSO')\n",
    "df_train['Destination'].unique() \n",
    "\n",
    "df_train['Age'].unique() #Tous les ages sont au même format. Après le traitement des NaNs ils seront mis en int\n",
    "\n",
    "df_train['VIP'].unique() #Tous les VIP sont au même format et pourront donc être mis en booléen après traitement des NaNs\n",
    "\n",
    "df_train['Transported'].unique() #Etant donné qu'il s'agit d'un booléen ce n'est pas étonnant \n",
    "\n",
    "df_train['PassengerGroupNumber'].unique() #Tous les numéros de groupes sont écrits au bon format \n",
    "\n",
    "df_train['Deck'].unique() #Tous les decks sont écrits au même format \n",
    "\n",
    "df_train['Side'].unique() #Tous les sides sont écrits au même format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame Test\n",
    "#Les variables qualitatives sont : HomePlanet, Destination, Age, VIP, Transported, PassengerGroupNumber, Deck, Side \n",
    "df_test['HomePlanet'].unique() #Toutes les planètes sont écrites au même format\n",
    "\n",
    "df_test['Destination'].unique() #Toutes les destinations sont écrites au même format\n",
    "#Il est décidé de simplifier les noms et de les mettre en majuscule \n",
    "df_test['Destination']=df_test['Destination'].replace('TRAPPIST-1e','TRAPPIST')\n",
    "df_test['Destination']=df_test['Destination'].replace('55 Cancri e','CANCRI')\n",
    "df_test['Destination']=df_test['Destination'].replace('PSO J318.5-22','PSO')\n",
    "df_test['Destination'].unique()\n",
    "\n",
    "df_test['Age'].unique() #Tous les ages sont au même format. Après le traitement des NaNs ils seront mis en int\n",
    "\n",
    "df_test['VIP'].unique() #Tous les VIP sont au même format et pourront donc être mis en booléen après traitement des NaNs\n",
    "\n",
    "df_test['PassengerGroupNumber'].unique() #Tous les numéros de groupes sont écrits au bon format \n",
    "\n",
    "df_test['Deck'].unique() #Tous les decks sont écrits au même format \n",
    "\n",
    "df_test['Side'].unique() #Tous les sides sont écrits au même format \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Détection et traitement des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Il y a',df_train.duplicated().sum(),'doublons dans le df train')\n",
    "print('Il y a',df_test.duplicated().sum(),'doublons dans le df test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Détection et traitement des valeurs manquantes\n",
    "\n",
    "Cette étape du nettoyage des jeux de données est critique pour les algorithmes de Machine Learning. Le traitement des NaNs aura nécessairement une influence sur le résultat final. Il convient donc de prendre les meilleurs hypothèses et d'en explorer plusieurs.\n",
    "\n",
    "L'objectif est de supprimer un minimum de données car plus on supprime de données, moins l'algorithme de Machine Learning aura de données pour s'entraîner. A contrario, si les NaNs sont remplacés par de mauvaises valeurs, cela bièsera l'algorithme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse globale\n",
    "display(pd.DataFrame(df_train.isna().sum(), columns=[\"Nombre de NA df train\"]))\n",
    "display(pd.DataFrame(df_test.isna().sum(), columns=[\"Nombre de NA df test\"]))\n",
    "#Oh. My. God."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Traitement des valeurs manquantes numériques\n",
    "\n",
    "Dans un premier temps nous allons suivre les hypothèses suivantes :\n",
    "- Pour l'âge nous allons remplacer les NaNs par la moyenne\n",
    "- Pour RoomService, FoodCourt, ShoppingMall, Spa et VRDeck nous allons remplacer les NaNs par 0 \n",
    "\n",
    "Il sera intéressant de faire autrement dans une seconde analyse afin d'observer l'influence de ces paramètres sur l'Accuracy des algorithmes de ML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On trie le df pour n'avoir que les valeurs numériques \n",
    "df_train.select_dtypes(include='number').isna().any()\n",
    "\n",
    "#DataFrame train\n",
    "\n",
    "#Age\n",
    "AgeMean=df_train['Age'].mean().round(0)\n",
    "df_train['Age']=df_train['Age'].fillna(AgeMean)\n",
    "#RoomService, FoodCourt, ShoppingMall, Spa et VRDeck\n",
    "df_train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']]=df_train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].fillna(0)\n",
    "\n",
    "#DataFrame test\n",
    "\n",
    "#Age\n",
    "AgeMean=df_test['Age'].mean().round(0) #Les moyennes d'age sont les mêmes dans les deux df\n",
    "df_test['Age']=df_test['Age'].fillna(AgeMean)\n",
    "#RoomService, FoodCourt, ShoppingMall, Spa et VRDeck\n",
    "df_test[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']]=df_test[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Traitement des valeurs manquantes catégorielles\n",
    "\n",
    "Dans un premier temps nous allons suivre les hypothèses suivantes. \n",
    "Etant donné que les valeurs ont été renseignées de manière ordonnée : \n",
    "- Pour HomePlanet, CryoSleep, nous allons chercher une logique avec les proches voisins \n",
    "- Pour CryoSleep aller chercher sur internet les distances : Peut etre que ceux qui viennent de plus loin ont décidé de se cryo\n",
    "- Pour VIP nous allons chercher une corrélation entre les dépenses annexes. En effet, on fait l'hypothèse qu'une personne ayant acheté des services à bord est plus susceptible d'avoir pris une formule VIP. Cependant, il faut garder à l'esprit que cet hypothèse est directement corrélée à l'hypothèse précédente sur les dépenses à bord\n",
    "- Pour Deck, Num et side nous allons chercher une logique avec les proches voisins. En effet, l'énoncé du concours indique que parfois certains passagers sont en famille. On peut également faire l'hypothèses (qui sera à vérifier en parcourant le dataset) que les passagers de mêmes groupes ont leur cabines à coté. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Deck.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On trie le df pour n'avoir que les valeurs catégorielles \n",
    "\n",
    "#DataFrame train\n",
    "\n",
    "#Destination\n",
    "data=df_train.pivot_table(index='HomePlanet', columns='Destination', aggfunc='size', fill_value=0)\n",
    "data=data.reset_index() #On observe que la plupart des gens vont à TRAPPIST. On décide donc de remplacer les NaNs \n",
    "df_train['Destination']=df_train['Destination'].fillna('TRAPPIST')\n",
    "\n",
    "#HomePlanet \n",
    "vip=df_train.pivot_table(index='HomePlanet', columns='VIP', aggfunc='size', fill_value=0)\n",
    "vip=vip.reset_index() #On remarque qu'aucune personne venant de Earth n'est VIP. \n",
    "df_train.loc[(df_train['HomePlanet'].isna()) & (df_train['VIP'] == True)]#On sait donc que ceux-là (291, 365, 405, 7042 et 7786) ne sont pas de Earth\n",
    "pd.crosstab(df_train.Destination, df_train.HomePlanet, normalize=0) \n",
    "#91% des gens qui vont à PSO viennent de Earth, 50% des gens qui vont à Cancri viennent d'Europa et 53% des gens qui vont à Trappist viennent de Earth \n",
    "#On met donc en place la boucle suivante pour associer à chaque NaN la HomePlanet la plus probable \n",
    "for index, row in df_train.iterrows(): #On parcourt chaque ligne du DataFrame\n",
    "    if pd.isna(row['HomePlanet']): #On vérifie que la valeur est bien un NaN\n",
    "        if row['Destination'] == 'CANCRI':\n",
    "            df_train.at[index, 'HomePlanet'] = 'Europa'\n",
    "        elif row['Destination'] == 'PSO':\n",
    "            df_train.at[index, 'HomePlanet'] = 'Earth'\n",
    "        elif row['Destination'] == 'TRAPPIST':\n",
    "            df_train.at[index, 'HomePlanet'] = 'Earth'\n",
    "pd.crosstab(df_train.Destination, df_train.HomePlanet, normalize=0) #On vérifie et OK, on a presque la même distribution \n",
    "\n",
    "#VIP\n",
    "df_train.VIP.value_counts(normalize=True) #On observe que 97% des passagers n'est pas en VIP. On remplace donc par le mode \n",
    "df_train['VIP']=df_train['VIP'].fillna(df_train['VIP'].mode()[0])\n",
    "\n",
    "#CryoSleep \n",
    "df_train.CryoSleep.value_counts(normalize=True) #On observe que 65% des passagers on choisi CryoSleep. Pas assez pour remplacer par le mode.  \n",
    "pd.crosstab(df_train.CryoSleep, df_train.VIP, normalize=1) #89% des VIP ne se cryogénisent pas donc si VIP = cryo non \n",
    "for index, row in df_train.iterrows():\n",
    "    if pd.isna(row['CryoSleep']):\n",
    "        if row['VIP'] == 'True':\n",
    "            df_train.at[index, 'CryoSleep'] = False\n",
    "        else:\n",
    "            df_train.at[index, 'CryoSleep'] = True\n",
    "\n",
    "#Deck, Num, Side \n",
    "#On observe que Deck, Num et side sont toujours simultanément des NaNs ensemble\n",
    "#Dans un premier temps je ne parviens pas à observer des liens me permettant de corriger ces NaNs. \n",
    "#Pour avancer je supprime ces NaNs en gardant à l'esprit que cela jouera sur l'Accuracy (il constituent 2% du dataset)\n",
    "df_train=df_train.dropna(axis = 0, how = 'any')\n",
    "\n",
    "\n",
    "#DataFrame test\n",
    "\n",
    "#Destination\n",
    "df_test['Destination']=df_test['Destination'].fillna('TRAPPIST')\n",
    "\n",
    "#HomePlanet\n",
    "for index, row in df_test.iterrows():\n",
    "    if pd.isna(row['HomePlanet']):\n",
    "        if row['Destination'] == 'CANCRI':\n",
    "            df_test.at[index, 'HomePlanet'] = 'Europa'\n",
    "        elif row['Destination'] == 'PSO':\n",
    "            df_test.at[index, 'HomePlanet'] = 'Earth'\n",
    "        elif row['Destination'] == 'TRAPPIST':\n",
    "            df_test.at[index, 'HomePlanet'] = 'Earth'\n",
    "\n",
    "#VIP\n",
    "df_test['VIP']=df_test['VIP'].fillna(df_test['VIP'].mode()[0])\n",
    "\n",
    "#CryoSleep \n",
    "for index, row in df_test.iterrows():\n",
    "    if pd.isna(row['CryoSleep']):\n",
    "        if row['VIP'] == 'True':\n",
    "            df_test.at[index, 'CryoSleep'] = False\n",
    "        else:\n",
    "            df_test.at[index, 'CryoSleep'] = True\n",
    "\n",
    "#Deck, Num, Side \n",
    "df_test=df_test.dropna(axis = 0, how = 'any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérification finale : \n",
    "display(pd.DataFrame(df_train.isna().sum(), columns=[\"Nombre de NA df train\"]))\n",
    "display(pd.DataFrame(df_test.isna().sum(), columns=[\"Nombre de NA df test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Deuxieme passe de traitement de la cohérence des données \n",
    "\n",
    "Certaines variabes n'ont pas pu être traitées avant le traitement des NaNs car ils en contenaient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame Train\n",
    "df_train['CryoSleep']=df_train['CryoSleep'].astype(bool)\n",
    "df_train[['Num','FoodCourt','Spa','RoomService','ShoppingMall','VRDeck','Age']]=df_train[['Num','FoodCourt','Spa','RoomService','ShoppingMall','VRDeck','Age']].astype(int)\n",
    "\n",
    "\n",
    "#Age a mettre en int\n",
    "#Room service a mettre en int (vérifier l'explication sur le site)\n",
    "\n",
    "#DataFrame Test\n",
    "df_test['CryoSleep']=df_test['CryoSleep'].astype(bool)\n",
    "df_test[['Num','FoodCourt','Spa','RoomService','ShoppingMall','VRDeck','Age']]=df_test[['Num','FoodCourt','Spa','RoomService','ShoppingMall','VRDeck','Age']].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Détection et traitement des Outliers\n",
    "Ce traitement ne concerne que les variables quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=df_train.select_dtypes(include='number')\n",
    "columns = num.columns\n",
    "\n",
    "plt.figure(figsize=(20, 15)) \n",
    "for i, col in enumerate(columns, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(y=num[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#On observe qu'il y a des outliers mais qui ne constituent pas des valeurs aberrantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2=df_test.select_dtypes(include='number')\n",
    "columns = num2.columns\n",
    "\n",
    "plt.figure(figsize=(20, 15)) \n",
    "for i, col in enumerate(columns, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(y=num2[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "\n",
    "#Idem que pour le précédent DataSet, on observe qu'il y a des outliers mais qui ne constituent pas des valeurs aberrantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etude de la distribution des âges \n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_train['Age'], bins=12, kde=True, color='red')\n",
    "plt.title(\"Distribution de l'âge dans le df train\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_test['Age'], bins=12, kde=True, color='blue')\n",
    "plt.title(\"Distribution de l'âge dans le df test\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L'idée est pour le sport de tester plusieurs algos de ML de classification et de pousser chaque étude au max en variant leurs hyperparamètres (GridSearchCV)\n",
    "#A la fin on fera un tableau récapitulatif montrant les meilleurs scores de chacun pour permettre de décider duquel choisir. \n",
    "#Il me semble que dans le premier notebook, il y avait une boucle permettant de faire ça.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : On veillera à regarder quelles sont les variables qui influent le plus sur ces algos de ML. Cela permettra de jouer sur leur étape de traitement des valeurs manquantes pour voir ce que ça fait vis a vis de l'accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Régression logistique\n",
    "### 1) Préparation et modélisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On copie les DataFrames pour effectuer des modifications dessus\n",
    "df_train_RL=df_train.copy()\n",
    "df_test_RL=df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrétisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age\n",
    "df_train_RL['Age']=pd.cut(x=df_train_RL['Age'], bins=[0,10,20,30,40,50,60,70,80], labels=['0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80'], include_lowest= True)\n",
    "df_test_RL['Age']=pd.cut(x=df_test_RL['Age'], bins=[0,10,20,30,40,50,60,70,80], labels=['0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80'], include_lowest= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation des variables explicatives de la variable à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train_RL.drop('Transported', axis=1)\n",
    "target = df_train_RL['Transported']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dichotomisation des variables\n",
    "\n",
    "La dichotomisation post train-test split prévient les fuites de données en évitant que des informations de l'ensemble de test n'influencent involontairement le modèle. En la réalisant après la division, elle assure également que le modèle est entraîné de manière à simuler un environnement réel, capable de gérer des catégories inconnues rencontrées dans de nouvelles données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L'objectif est de ne plus avoir de variables qualitatives. En effet, certains modèles de ML sont incapables d'interpréter des variables qualitatives\n",
    "\n",
    "#DataFrame Train\n",
    "\n",
    "enc=preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_enc=enc.fit_transform(X_train)\n",
    "X_test_enc=enc.transform(X_test)\n",
    "\n",
    "#DataFrame Test\n",
    "\n",
    "df_test_RL_enc=enc.transform(df_test_RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Premier modèle de régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction du classifieur \n",
    "clf=linear_model.LogisticRegression(C=1.0, max_iter=1000)\n",
    "#Entrainement de l'algorithme sur l'ensemble d'entrainement\n",
    "clf.fit(X_train_enc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation du modèle\n",
    "y_pred=clf.predict(X_test_enc)\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = clf.score(X_train_enc, y_train)\n",
    "print(\"L'accuracy du modèle d'entrainement est\",accuracy )\n",
    "accuracy = clf.score(X_test_enc, y_test)\n",
    "print(\"L'accuracy du modèle de test est\",accuracy )\n",
    "print(\"Il y a énormément d'overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modification du seuil de précision\n",
    "probs = clf.predict_proba(X_test_enc)\n",
    "y_preds = np.where(probs[:,1]>0.4,1,0)\n",
    "cm = pd.crosstab(y_test, y_preds, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "cm #Toujours pas foufou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce premier modèle de classification est mauvais. En effet, la différence d'accuracy est énorme entre le modèle d'entrainement et le modèle de test. Un telle différence implique un phénomène de sur-apprentissage (overfitting). Il faut à tout prix éviter cela.\n",
    "\n",
    "Il convient donc d'étudier le réglage des hyperparamètres du modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Affinage du modèle et réglage des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'un dictionnaire comprenant les valeurs possibles pour les hyperparamètres \n",
    "parametres = {\n",
    "    'C': np.arange(0.1, 1, 0.1),\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'solver': ['liblinear', 'saga'], \n",
    "    'max_iter': [1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_regLog = model_selection.GridSearchCV(estimator=clf, param_grid=parametres, cv=3, n_jobs=-1) #Application de la fonction au classifieur\n",
    "grille = grid_regLog.fit(X_train_enc,y_train) #Entrainement sur l'ensemble d'entrainement\n",
    "print(pd.DataFrame.from_dict(grille.cv_results_).loc[:,['params', 'mean_test_score']]) #Fonctionne en 15secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_regLog.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_regLog.predict(X_test_enc)\n",
    "pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train_RL = grid_regLog.score(X_train_enc, y_train)\n",
    "print(\"L'accuracy du modèle d'entrainement est\",accuracy_train_RL )\n",
    "accuracy_test_RL = grid_regLog.score(X_test_enc, y_test)\n",
    "print(\"L'accuracy du modèle de test est\",accuracy_test_RL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impression du rapport de classification \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'overfitting est considérablement réduit, mais n'est toujours pas satisfaisant. Le score global est trop faible.\n",
    "Le modèle de régression linéaire................................................................................................ dire qu'on s'y attendait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) KNN (K Nearest Neighbors)\n",
    "### 1) Préparation et modélisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On copie les DataFrames pour effectuer des modifications dessus\n",
    "df_train_KNN=df_train.copy()\n",
    "df_test_KNN=df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation des variables explicatives de la variable à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_train_KNN.drop('Transported', axis=1)\n",
    "target=df_train_KNN['Transported']\n",
    "target =  [1 if x==True else 0 for x in target]\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation des variables catégorielles en variables binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix=pd.get_dummies(data, dtype=float)\n",
    "data_matrix.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_matrix, target, test_size = 0.2, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dichotomisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Premier modèle de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction du classifieur \n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=7, metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustement de l'algorithme sur l'ensemble d'entrainement\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation du modèle\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "cm=pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = knn.score(X_train_scaled, y_train)\n",
    "print(\"L'accuracy du modèle d'entrainement est\",accuracy )\n",
    "accuracy = knn.score(X_test_scaled, y_test)\n",
    "print(\"L'accuracy du modèle de test est\",accuracy )\n",
    "print(\"On observe qu'il y a tout de même un peu d'overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Affinage du modèle et réglage des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'un dictionnaire comprenant les valeurs possibles pour les hyperparamètres \n",
    "parametres = {'n_neighbors' : np.arange(2, 16, 1),\n",
    "              'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'metric' : ['manhattan', 'chebyshev', 'minkowski']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn = model_selection.GridSearchCV(estimator=knn, param_grid=parametres, cv=5) #Application de la fonction au classifieur\n",
    "grille = grid_knn.fit(X_train_scaled,y_train) #Entrainement sur l'ensemble d'entrainement\n",
    "print(pd.DataFrame.from_dict(grille.cv_results_).loc[:,['params', 'mean_test_score']]) #Fonctionne en 2mins17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_knn.predict(X_test_scaled)\n",
    "pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train_knn = grid_knn.score(X_train_scaled, y_train)\n",
    "print(\"L'accuracy du modèle d'entrainement est\",accuracy_train_knn )\n",
    "accuracy_test_knn = grid_knn.score(X_test_scaled, y_test)\n",
    "print(\"L'accuracy du modèle de test est\",accuracy_test_knn )\n",
    "#On a réduit l'overfitting mais on a également réduit la précision du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impression du rapport de classification \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Support Vector Machine (SVM)\n",
    "### 1) Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On copie les DataFrames pour effectuer des modifications dessus\n",
    "df_train_SVM=df_train.copy()\n",
    "df_test_SVM=df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation des variables explicatives de la variable à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_train_SVM.drop('Transported', axis=1)\n",
    "target=df_train_SVM['Transported']\n",
    "target =  [1 if x==True else 0 for x in target]\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation des variables catégorielles en variables binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix=pd.get_dummies(data, dtype=float)\n",
    "data_matrix.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_matrix, target, test_size = 0.2, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dichotomisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Premier modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction du classifieur \n",
    "clf_svm=svm.SVC(gamma=0.01, kernel = 'poly')\n",
    "#Evaluation du modèle\n",
    "clf_svm.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation du modèle\n",
    "y_pred=clf_svm.predict(X_test_scaled)\n",
    "pd.crosstab(y_test,y_pred,rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = clf_svm.score(X_train_scaled, y_train)\n",
    "print(\"L'accuracy du modèle d'entrainement est\",accuracy )\n",
    "accuracy = clf_svm.score(X_test_scaled, y_test)\n",
    "print(\"L'accuracy du modèle de test est\",accuracy )\n",
    "print(\"Le score est intérressant car il n'y a pas d'overfitting !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Affinage du modèle et réglage des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametres = {'C':[0.1,1,10], \n",
    "              'kernel':['rbf','linear','poly'], \n",
    "              'gamma':[0.001, 0.1, 1]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svm = model_selection.GridSearchCV(estimator=clf_svm, param_grid=parametres, cv=5) #Application de la fonction au classifieur\n",
    "grille = grid_svm.fit(X_train_scaled,y_train) #Entrainement sur l'ensemble d'entrainement\n",
    "print(pd.DataFrame.from_dict(grille.cv_results_).loc[:,['params', 'mean_test_score']]) #Fonctionne en mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_svm.predict(X_test_scaled)\n",
    "pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train_svm = grid_knn.score(X_train_scaled, y_train)\n",
    "print(\"L'accuracy du modèle d'entrainement est\",accuracy_train_svm )\n",
    "accuracy_test_svm = grid_knn.score(X_test_scaled, y_test)\n",
    "print(\"L'accuracy du modèle de test est\",accuracy_test_svm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impression du rapport de classification \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTENTION IL FAUDRA AUSSI APPLIQUER LES MEMES PREPROCESSING AU DF TEST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAIRE UN TABLEAU RECAPITULATIF DE TOUTES LES ACCURACY POUR LES COMPARER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aide pour NaNs : https://www.kaggle.com/competitions/spaceship-titanic/discussion/315987"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-spaceship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
